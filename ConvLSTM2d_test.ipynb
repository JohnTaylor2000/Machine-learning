{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM2d_test.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTwbGxFa8pRe7wD+RRQWIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnTaylor2000/Machine-learning/blob/master/ConvLSTM2d_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeTwjuyiN7IK",
        "colab_type": "text"
      },
      "source": [
        "**Title**: Next-frame prediction with Conv-LSTM\n",
        "**Author**: [jeammimi](https://github.com/jeammimi)\n",
        "**Date created**: 2016/11/02\n",
        "**Last modified:** 2020/06/01\n",
        "\n",
        "**Description:** Predict the next frame in a sequence using a Conv-LSTM model.\n",
        "\n",
        "**Adapted:** by John Taylor 2020/07 to run in google colab in an easy interactive form, fixed an error with the model that prevented time series predictions working properly. Included updated version of plotting of the future frames, train and test history and activations.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This script demonstrates the use of a convolutional LSTM model.\n",
        "The model is used to predict the next frame of an artificially\n",
        "generated movie which contains moving squares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-fR6puOdXD",
        "colab_type": "text"
      },
      "source": [
        "Start by loading **Nvidia GPU environment** variables that suppress warning messages. Only needed when running on nvidia GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQOoMHSzOyxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_DISABLE_NVTX_RANGES\"] = \"1\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "os.environ[\"NCCL_DEBUG\"] = \"WARN\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG6bsIJGO9vs",
        "colab_type": "text"
      },
      "source": [
        "Add **Matplotlib** plotting library and **Numpy** maths library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmtf5e24PHP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph06BJYsbRo0",
        "colab_type": "text"
      },
      "source": [
        "Add the **time** library so we can time code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK-Bu4SebS5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9mwq8EdPUyo",
        "colab_type": "text"
      },
      "source": [
        "Add **TensorFlow** - we will use Keras to create the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwSsXk5bPhRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Conv3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7T_ePHLbWZl",
        "colab_type": "text"
      },
      "source": [
        "**Test for the presence of a GPU device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXbYs9cxarCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Kf0nh0U3AC",
        "colab_type": "text"
      },
      "source": [
        "**Set Key parameters**\n",
        "\n",
        "Select the **frame size, number of filters and layers** in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Jh_LHHF5N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame_size = 40   # number of pixels in x and y dimensions\n",
        "n_frames = 20\n",
        "noise = True      # Add noise during training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF5vHgX9MzLw",
        "colab_type": "text"
      },
      "source": [
        "**Model related parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--h3Zd7uMnwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters = 64    # base number of hidden units\n",
        "nrows = 8           # Plot nrows by ncols matrix of hidden units\n",
        "ncols = 8           # *** must be factors of num_filters ***\n",
        "\n",
        "num_layers = 4      # number of layers in addition to input and output layer\n",
        "scale_fac = 1       # increase the number of hidden units per layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGevCZnGM6zw",
        "colab_type": "text"
      },
      "source": [
        "**Training related parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqHejPx0MrfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10     # In practice, for real applications you would need hundreds of epochs.\n",
        "n_samples  = 1200   # This is the number of frames for test and validation\n",
        "batch_size = 10     # Batch size "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJWZj_lVQ1k5",
        "colab_type": "text"
      },
      "source": [
        "**Build and Compile the Model**\n",
        "\n",
        "We create a model which take as input movies of shape\n",
        "`(n_frames, width, height, channels)` and returns a movie\n",
        "of identical shape.\n",
        "We set Variable-length sequence of 40x40x1 frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD-BQeHwL2X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Input(shape=(None, frame_size, frame_size, 1)))\n",
        "\n",
        "if num_layers > 0:\n",
        "  scale = scale_fac\n",
        "  for i in range (num_layers):\n",
        "    model.add(ConvLSTM2D(filters=num_filters*scale, kernel_size=(3, 3), padding=\"same\", return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    scale = scale * scale_fac\n",
        "\n",
        "# Output layer - must set first parameter in kernel size = 1 to track movement using LSTM\n",
        "model.add(Conv3D(filters=1, kernel_size=(1, 3, 3), activation=\"sigmoid\", padding=\"same\"))\n",
        "  \n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "#model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6RK46NaXnQq",
        "colab_type": "text"
      },
      "source": [
        "**Print a summary of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C_riq0TXuTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gKqZIamYlEJ",
        "colab_type": "text"
      },
      "source": [
        "**Generate artificial data**\n",
        "\n",
        "Generate movies with 3 to 7 moving squares inside.\n",
        "The squares are of shape 1x1 or 2x2 pixels,\n",
        "and move linearly over time.\n",
        "\n",
        "For convenience, we first create movies with bigger width and height (80x80)\n",
        "and at the end we select a 40x40 window.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-67VbB7jWU43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 5 to 10 moving squares\n",
        "        n = np.random.randint(5, 10)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "           # directionx = np.random.randint(0, 3) - 1\n",
        "            directionx = np.random.randint(0, 5) - 1\n",
        "            directiony = np.random.randint(0, 5) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[\n",
        "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
        "                ] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the model to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "              \n",
        "                if np.random.randint(0, 2) and noise:\n",
        "                    noise_f = (-1) ** np.random.randint(0, 2)\n",
        "                    noisy_movies[\n",
        "                        i,\n",
        "                        t,\n",
        "                        x_shift - w - 1 : x_shift + w + 1,\n",
        "                        y_shift - w - 1 : y_shift + w + 1,\n",
        "                        0,\n",
        "                    ] += (noise_f * 0.1)\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[\n",
        "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, 0\n",
        "                ] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    \n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "#noisy_movies, shifted_movies = generate_movies(n_samples)\n",
        "#for i in range(40):\n",
        "#  print (noisy_movies[1,1,i,:40,0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS5VTCAzW6td",
        "colab_type": "text"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLVni_6bWdTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples, n_frames)\n",
        "\n",
        "history = model.fit(\n",
        "    noisy_movies[:1000],\n",
        "    shifted_movies[:1000],\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    verbose=1,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "elapsed_time = time.time() - t0\n",
        "print (' Model Train Elapsed Time (sec) = ', elapsed_time)\n",
        "print (' Completed ', num_epochs, ' Epochs.', ' Elapsed Time (sec) = ', elapsed_time)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EemI5bLMbwmC",
        "colab_type": "text"
      },
      "source": [
        "**Plot the train and test model history**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j3OgFPub2KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoD9eIzUWtfy",
        "colab_type": "text"
      },
      "source": [
        "**Test the model on one movie**\n",
        "\n",
        "Feed it with the first 7 positions and then\n",
        "predict the new positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaeoN3NiPBoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_index = 1004\n",
        "test_movie = noisy_movies[movie_index]\n",
        "\n",
        "# Start from first 7 frames\n",
        "track = test_movie[:7, ::, ::, ::]\n",
        "\n",
        "# Predict frames\n",
        "for j in range(n_frames):\n",
        "    print(j)\n",
        "    new_pos = model.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "track2 = noisy_movies[movie_index][::, ::, ::, ::]\n",
        "for i in range(n_frames-1):\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='b')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20, color='b')\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot, cmap=\"cool\")\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', color='b', fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[movie_index][i - 1, ::, ::, 0]\n",
        "    plt.imshow(toplot, cmap=\"cool\")\n",
        "    # plt.savefig('%i_animate.png' % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbooyQIpzbq",
        "colab_type": "text"
      },
      "source": [
        "**Plot the activations for each layer**\n",
        "\n",
        "To do this we first build a model using the model we have just trained that takes the input data, as defined above, and produces the corresponding activations as output. Note that the final layer has only one dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzDUujZp2A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_names=[layer.name for layer in model.layers]\n",
        "layer_outputs = [layer.output for layer in model.layers[:num_layers+2]]\n",
        "activation_model = models.Model(inputs=model.input,outputs=layer_outputs)\n",
        "activations = activation_model.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "activations = np.array(activations)\n",
        "\n",
        "ts = n_frames+6 # last time step predicted\n",
        "\n",
        "for i in range(num_layers+2):\n",
        "  \n",
        "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(9, 9),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})  \n",
        "  \n",
        "  for j in range (nrows):\n",
        "    for k in range (ncols):\n",
        "      iout = k + j*ncols\n",
        "      axs[j,k].imshow(activations[i, 0, ts, :, :, iout], cmap='jet')\n",
        "      \n",
        "  fig.suptitle('Activations - ' + layer_names[i] + ' - Hidden Units - ' + '0 to ' + str(nrows*ncols), y=1.02)\n",
        "  plt.tight_layout()      \n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFWsoTDxeuRV",
        "colab_type": "text"
      },
      "source": [
        "**Plot the weights for each convolutional layer**\n",
        "\n",
        "Skip the input and output layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJiQPe_8et3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_names=[layer.name for layer in model.layers]\n",
        "\n",
        "for i in range(len(layer_names)-1):\n",
        "\n",
        "  weights = model.layers[i].get_weights()[0]\n",
        "\n",
        "# plot weights for convolutional layers only\n",
        "\n",
        "  if weights.ndim > 1 and weights.shape[2] > 1 :\n",
        "    nrows = weights.shape[0]\n",
        "    ncols = weights.shape[1]\n",
        "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 4),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})  \n",
        "    w_min = weights.min()\n",
        "    w_max = weights.max()\n",
        "\n",
        "    for j in range (nrows):\n",
        "      for k in range (ncols):\n",
        "        im = axs[j,k].imshow(weights[j,k,:,:], cmap='jet',vmin=w_min, vmax=w_max)\n",
        "        \n",
        "    fig.subplots_adjust(right=1.2)\n",
        "    fig.colorbar(im, ax=axs.ravel().tolist())\n",
        "    fig.suptitle('Weights - ' + layer_names[i], y=1.03)\n",
        "    plt.tight_layout()      \n",
        "    plt.show() \n",
        "    # add a plot of the histogram of the weights\n",
        "    plt.hist(weights.flatten(), bins =50)  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}